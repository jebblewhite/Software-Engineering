{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Big O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Software Engineers will spend a significant amount of his time improving the efficiency of the code: __a faster algorithm__\n",
    "\n",
    "The search of this efficiency lead to the development of different methods and normalize that method to analyze every algorithm under the same conditions. \n",
    "\n",
    "This efficiency measurement is known as asymptotic analysis, and it will tell us the computational cost (or complexity) of an algorithm as a function of different parameters, for example its input size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Complexity\n",
    "Imagine a simple for loop that iterates through n elements:\n",
    "`for i in range(20)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](images/BigO_1.gif)\n",
    "\n",
    "Now, imagine a nested for loop:\n",
    "```\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "```\n",
    "\n",
    "![](images/BigO_2.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first graph means that the amount of time the code takes to run increases proportional to the number of inputs\n",
    "\n",
    "Second second graph means that the amount of time the code takes to run increases proportional to the square of the number of inputs.\n",
    "\n",
    "There is a shorthand to write this: Big O notation, which represents the time complexity in the worst case scenario. \n",
    "\n",
    "It looks like this: `O(n^2)`, where n is the number of inputs, and n^2 is the time complexity. Thus for the first case we have `O(n)` and for the second case `O(n^2)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worst case scenario? What is the WCS for a for loop? Imagine we are looking for a specific number in the list. The WCS would be finding it at the end of it.\n",
    "\n",
    "_Same way we have big O, we also have big Ω for Best Case Scenario, and big θ for a combination of both. However we will focus solely on the big O_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know how complexity increases in nested loops, you might think twice before using one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: \n",
    "\n",
    "What is the big O of the following codes?\n",
    "```\n",
    "for x in range(n):\n",
    "    do something\n",
    "for y in range(m):\n",
    "    do something\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "for x in range(n):\n",
    "    do something\n",
    "    for y in range(m):\n",
    "        do something\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a rule of thumb:\n",
    "> If your algorithm is in the form 'Do this, then do that' you add the complexities\n",
    "> \n",
    "> If your algorithm is in the form 'Do this every time you do that' you multiply the complexities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, big O notation measures the times your input will be processed (in the worst-case scenario). So if you see for example\n",
    "```\n",
    "for x in range(len(n)):\n",
    "    y = 3 * x\n",
    "```\n",
    "The time complexity is not O(3n), it is still O(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Fibonacci big O\n",
    "Let's see an classical example: Recursive Fibonacci vs Loop Fibonacci "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recur_fibo(n):\n",
    "   if n <= 1:\n",
    "       return n\n",
    "   else:\n",
    "       return(recur_fibo(n-1) + recur_fibo(n-2))\n",
    "\n",
    "\n",
    "# check if the number of terms is valid\n",
    "def while_fib(n):\n",
    "    n1, n2 = 0, 1\n",
    "    count = 0\n",
    "    while count < n - 1:\n",
    "        nth = n1 + n2\n",
    "        # update values\n",
    "        n1 = n2\n",
    "        n2 = nth\n",
    "        count += 1\n",
    "    return nth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's time each function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102334155\n",
      "Recursive Fib took 51.17477893829346 s\n",
      "102334155\n",
      "While Fib took 0.00014495849609375 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "n = 40\n",
    "t_0 = time.time()\n",
    "print(recur_fibo(n))\n",
    "print(f'Recursive Fib took {time.time() - t_0} s')\n",
    "\n",
    "\n",
    "t_0 = time.time()\n",
    "print(while_fib(n))\n",
    "print(f'While Fib took {time.time() - t_0} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra points to anyone who can tell me the big O of each algorithm. You can google it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Space Complexity\n",
    "\n",
    "We just talked about time complexity, but we should also consider space complexity. It can also be measured using the big O, and in essence measures the amount of memory allocated to run your program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, O(n) means that for each input processed, you will add one variable per processed input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space Complexity of Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating through lists, dictionaries, sets or tuples usually has a linear Big O (`O(n)`) in terms of time complexity. But fetching specific items is speedy in dictionaries and sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4}\n",
    "my_list = ['One', 'Two', 'Three', 'Four']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we might not see a difference when checking if 'Three' exists for example, but for huge data inputs, dictionaries are much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generators - A solution for Space complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing all information in a list will take `O(n)` in terms of space complexity. Thus, huge datasets takes huge data complexity. \n",
    "\n",
    "Instead, try using generators, since they take a `O(1)` (as long as we don't append its values in another list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "def my_gen(n):\n",
    "    for i in range(n):\n",
    "        yield i\n",
    "\n",
    "y = my_gen(20)\n",
    "s = next(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(getsizeof(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "s = next(y)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that we only have one variable for iterating through 20 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n"
     ]
    }
   ],
   "source": [
    "print(getsizeof(my_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating through `my_list` will take the same time complexity, but we need a list with 20 memory allocations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Big O possibilites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big O can show many complexities, and as we progress in this Unit, we will see more them.\n",
    "\n",
    "![](images/BigO_3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/BigO_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the above graph, it looks like if the input size is low, some algorithms are better. For example, O(n^2) looks better than O(n) at the beggining. But don't get fooled! That is only true if the input size is less than 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this unit, we will see alternative to the data structures we have seen so far. We will learn about the following data structures:\n",
    " 1. Linked List\n",
    " 2. Stack and Queue\n",
    " 3. Binary Trees \n",
    " 4. Binary Search Tree\n",
    " 5. Graphs\n",
    "\n",
    "Additionally, we will learn about the following algorithms:\n",
    " 1. Sorting\n",
    " 2. Searching\n",
    " 3. Recursion\n",
    " 4. Memoization and Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last word on Big O. Identify where your code presents a bottleneck: which part slows down the whole algorithm, and try to come up with a better algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look information about the next topics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Look information about default dictionaries in python. What is its average time complexity?\n",
    "### Q1.2 Get familiar with defaultdict! We will be using it during the course [DefaultDict](https://realpython.com/python-defaultdict/)\n",
    "### Q2. Look infomation about Counter in python. What is its average time complexity?\n",
    "### Q3. What does small o mean?\n",
    "### Q4. What does small ω mean?\n",
    "### Q5. How would you process a text file so the __space__ complexity is O(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Big_O_notation)\n",
    "\n",
    "[Big O Notation](https://www.freecodecamp.org/news/big-o-notation-why-it-matters-and-why-it-doesnt-1674cfa8a23c/)\n",
    "\n",
    "[Introduction to the theory of computation](http://fuuu.be/polytech/INFOF408/Introduction-To-The-Theory-Of-Computation-Michael-Sipser.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "569d6b7e9215e11aba41c6454007e5c1b78bad7df09dab765d8cf00362c40f03"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}